# SMC Trading Model Pipeline

Production-ready machine learning pipeline for Smart Money Concepts (SMC) trade prediction.

## ğŸ¯ Quick Start

### Kaggle Execution
```bash
# Clone repository
git clone https://github.com/Morriase/integrated-pipeline.git
cd integrated-pipeline

# Install dependencies
pip install --upgrade scikit-learn imbalanced-learn

# Run complete pipeline
python run_complete_pipeline.py  # Data preparation
python train_all_models.py       # Train models
python create_training_visualizations.py  # Generate charts
python test_consensus_ensemble.py  # Test ensemble
```

### Local Execution
Same commands work locally. Data paths auto-detect environment.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ consolidate_mt5_data.py          # MT5 data consolidation
â”œâ”€â”€ data_preparation_pipeline.py     # SMC feature engineering
â”œâ”€â”€ run_complete_pipeline.py         # Complete data pipeline
â”œâ”€â”€ train_all_models.py              # Train all models
â”œâ”€â”€ test_consensus_ensemble.py       # Test ensemble voting
â”œâ”€â”€ create_training_visualizations.py # Generate charts
â”œâ”€â”€ run_kaggle_pipeline.py           # All-in-one Kaggle script
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ base_model.py                # Base model class
â”‚   â”œâ”€â”€ random_forest_model.py       # RandomForest
â”‚   â”œâ”€â”€ xgboost_model.py             # XGBoost
â”‚   â”œâ”€â”€ neural_network_model.py      # Neural Network (BEST)
â”‚   â”œâ”€â”€ lstm_model.py                # LSTM (experimental)
â”‚   â”œâ”€â”€ ensemble_model.py            # Consensus ensemble
â”‚   â”œâ”€â”€ config.py                    # Model configurations
â”‚   â”œâ”€â”€ overfitting_monitor.py       # Training monitor
â”‚   â””â”€â”€ data_augmentation.py         # Data augmentation
â”‚
â”œâ”€â”€ Docs/
â”‚   â”œâ”€â”€ DATA_FLOW_ANALYSIS.md        # Complete pipeline analysis
â”‚   â”œâ”€â”€ GAPS_SUMMARY.md              # Known issues & fixes
â”‚   â””â”€â”€ training_progress.txt        # Latest training results
â”‚
â””â”€â”€ resources/                        # Training logs & summaries
```

---

## ğŸš€ Model Performance

| Model | Test Acc | Win Rate | Profit Factor | EV/Trade | Status |
|-------|----------|----------|---------------|----------|--------|
| **Neural Network** | 64.8% | 57.2% | 2.67 | **0.72R** | â­ BEST |
| RandomForest | 61.5% | 50.6% | 2.05 | 0.52R | âœ… Stable |
| XGBoost | 72.2% | 42.8% | 1.50 | 0.28R | âœ… Accurate |
| LSTM | 46.4% | 47.6% | 1.82 | 0.43R | âš ï¸ Unstable |

**Recommendation:** Deploy Neural Network as primary model.

---

## ğŸ“Š Training Data

- **Total Samples:** 110,000 candles
- **Labeled Setups:** 2,630 (3.4% - high-quality SMC setups only)
- **Symbols:** 11 (EURUSD, GBPUSD, USDJPY, etc.)
- **Timeframes:** 7 (M1, M5, M15, M30, H1, H4, D1)
- **Features:** 100+ (ATR-normalized, fuzzy logic)
- **Split:** 70% train, 15% val, 15% test

---

## ğŸ¯ Production Deployment

### Recommended Strategy: Hybrid Ensemble

```python
# Primary: Neural Network (best EV)
nn_pred = neural_network.predict(X)

# Validators: RF + XGB
rf_pred = random_forest.predict(X)
xgb_pred = xgboost.predict(X)

# Scale position by agreement
if nn_pred == rf_pred == xgb_pred:
    position_size = 1.0%  # High confidence
elif (nn_pred == rf_pred) or (nn_pred == xgb_pred):
    position_size = 0.75%  # Medium confidence
else:
    position_size = 0.5%  # Low confidence (NN only)
```

### Expected Performance
```
Win Rate: 57.2%
Expected Value: 0.72R per trade
Profit Factor: 2.67

100 trades @ 1% risk = +72% account growth
```

---

## ğŸ“ˆ Visualizations

Generated in `/kaggle/working/Training_Images/`:
- `model_comparison.png` - Performance comparison
- `confusion_matrices.png` - Prediction matrices
- `training_curves_comparison.png` - Loss & accuracy curves
- `overfitting_analysis.png` - Train-val gaps
- `training_summary.png` - Overall metrics

---

## ğŸ”§ Configuration

### Kaggle Paths (Auto-Detected)
```
Input:  /kaggle/input/ob-ai-model-2-dataset/Data/mt5_exports
Data:   /kaggle/working/Data-output
Models: /kaggle/working/Model-output
Images: /kaggle/working/Training_Images
```

### Local Paths (Fallback)
```
Input:  Data/mt5_exports
Data:   Data
Models: models/trained
Images: Training_Images
```

---

## ğŸ“š Documentation

- **`KAGGLE_QUICK_START.md`** - Quick start guide
- **`Docs/DATA_FLOW_ANALYSIS.md`** - Complete pipeline breakdown
- **`Docs/GAPS_SUMMARY.md`** - Known issues & solutions
- **`models/CONFIG_DOCUMENTATION.md`** - Model configurations

---

## âš™ï¸ Key Features

### Data Pipeline
- âœ… Multi-symbol consolidation
- âœ… SMC feature extraction (OB, FVG, BOS, ChoCH)
- âœ… Fuzzy logic for adaptive thresholds
- âœ… ATR normalization for cross-symbol compatibility
- âœ… Triple Barrier Method labeling

### Model Training
- âœ… Unified dataset approach (all symbols)
- âœ… Feature selection (100+ â†’ 30-50 features)
- âœ… Class weight balancing
- âœ… Cross-validation
- âœ… Early stopping
- âœ… Overfitting monitoring
- âœ… Trading metrics (win rate, profit factor, EV)

### Ensemble
- âœ… Consensus voting (strict/majority)
- âœ… Confidence filtering
- âœ… Hybrid strategies

---

## ğŸ› ï¸ Requirements

```
Python 3.8+
pandas
numpy
scikit-learn
xgboost
torch (for NN/LSTM)
matplotlib
seaborn
imbalanced-learn
```

---

## ğŸ“ License

MIT License - See LICENSE file

---

## ğŸ‰ Status

**Production Ready** - All models trained, tested, and validated.

Neural Network achieves **0.72R expected value per trade** with **57.2% win rate**.

Ready for paper trading and live deployment.
