================================================================================
SMC MODEL TRAINING - FULL DATASET APPROACH
================================================================================

üéØ Training Strategy:
  - Train on ALL symbols combined (unified dataset)
  - 2,500+ samples (vs 178-295 per symbol)
  - 3 models total (vs 44 models)
  - Better generalization, less overfitting
  - ATR normalization makes features comparable
üîç Detected Kaggle environment
  ‚úì Using cleaned data (optimized for Neural Network)
üìÇ Data Directory: /kaggle/working/Data-output-clean
üìÇ Model Output Directory: /kaggle/working/Model-output

üîç Checking data availability...
  ‚úì Train data: /kaggle/working/Data-output-clean/processed_smc_data_train_clean.csv
  ‚úì Val data:   /kaggle/working/Data-output-clean/processed_smc_data_val_clean.csv
  ‚úì Test data:  /kaggle/working/Data-output-clean/processed_smc_data_test_clean.csv

üìä Dataset Statistics:
  Train samples: 10,050
  Val samples:   2,159
  Test samples:  2,129
  Total:         14,338
  Symbols:       11
  Features:      78

================================================================================
STARTING UNIFIED TRAINING
================================================================================

################################################################################
# Training All Models on UNIFIED DATASET
################################################################################

üéØ Strategy: Train on ALL data for maximum generalization
   Core Models: RandomForest, XGBoost, NeuralNetwork
   LSTM: Disabled (use --include-lstm to enable)

üå≤ Starting RandomForest training...

================================================================================
Training Random Forest on FULL UNIFIED DATASET
================================================================================

üìä Training on FULL dataset:
  Train: 10,050 samples (11 symbols)
  Val:   2,159 samples
  Test:  2,129 samples
  Selected 53 features
  Remapped labels: [0 1]

üîÑ Performing 5-fold cross-validation...

üîÑ Performing 5-fold cross-validation...

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.650
  Val accuracy:   0.663
  Train-Val gap:  -0.013
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 1/5: Accuracy=0.663, F1=0.625

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.654
  Val accuracy:   0.648
  Train-Val gap:  0.006
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 2/5: Accuracy=0.648, F1=0.610

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.652
  Val accuracy:   0.659
  Train-Val gap:  -0.008
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 3/5: Accuracy=0.659, F1=0.622

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.652
  Val accuracy:   0.658
  Train-Val gap:  -0.006
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 4/5: Accuracy=0.658, F1=0.621

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.657
  Val accuracy:   0.638
  Train-Val gap:  0.019
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 5/5: Accuracy=0.638, F1=0.603

  Cross-Validation Results:
    Mean Accuracy: 0.653 ¬± 0.009
    Min Accuracy:  0.638
    Max Accuracy:  0.663
    Range:         0.025
    Mean F1-Score: 0.616 ¬± 0.008
    ‚úÖ STABLE: Std dev 0.009 ‚â§ 0.10

    Poor-Performing Folds (below mean - std):
      Fold 5: 0.638 (deviation: -0.015)

üìà Cross-Validation Results:
  Mean Accuracy: 0.6532 ¬± 0.0091
  Stability: ‚úÖ Stable

üéØ Training final model...

üå≤ Training Random Forest for UNIFIED...
  Training samples: 10,050
  Features: 53

  üîÑ Performing cross-validation...

üîÑ Performing 5-fold cross-validation...

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.650
  Val accuracy:   0.663
  Train-Val gap:  -0.013
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 1/5: Accuracy=0.663, F1=0.625

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.654
  Val accuracy:   0.648
  Train-Val gap:  0.006
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 2/5: Accuracy=0.648, F1=0.610

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.652
  Val accuracy:   0.659
  Train-Val gap:  -0.008
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 3/5: Accuracy=0.659, F1=0.622

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.652
  Val accuracy:   0.658
  Train-Val gap:  -0.006
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 4/5: Accuracy=0.658, F1=0.621

üå≤ Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.657
  Val accuracy:   0.638
  Train-Val gap:  0.019
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Feature importance computed (feature names not available)
  Fold 5/5: Accuracy=0.638, F1=0.603

  Cross-Validation Results:
    Mean Accuracy: 0.653 ¬± 0.009
    Min Accuracy:  0.638
    Max Accuracy:  0.663
    Range:         0.025
    Mean F1-Score: 0.616 ¬± 0.008
    ‚úÖ STABLE: Std dev 0.009 ‚â§ 0.10

    Poor-Performing Folds (below mean - std):
      Fold 5: 0.638 (deviation: -0.015)

  Train accuracy: 0.653
  Val accuracy:   0.661
  Train-Val gap:  -0.008
  ‚úÖ Good generalization (gap ‚â§ 15%)

  Top 10 Most Important Features:
    TBM_Bars_to_Hit                         : 0.2863
    TBM_Reward_Per_Trade_ATR                : 0.1346
    TBM_Risk_Per_Trade_ATR                  : 0.0980
    FVG_Depth_ATR_ZScore                    : 0.0795
    FVG_Quality_Fuzzy                       : 0.0764
    FVG_Depth_ATR                           : 0.0653
    FVG_Size_Fuzzy_Score                    : 0.0595
    FVG_Distance_to_Price_ATR_ZScore        : 0.0468
    FVG_Distance_to_Price_ATR               : 0.0446
    FVG_Mitigated                           : 0.0428

üìä Evaluating on Validation set...

  Classification Metrics:
    Accuracy: 0.661
    Precision (macro): 0.662
    Recall (macro): 0.746
    F1-Score (macro): 0.630

  Trading Metrics (1:2.0 R:R):
    Win Rate: 100.0% (1077/1077 trades)
    Profit Factor: inf
    Expected Value/Trade: 2.00R
    Trade Accuracy: 100.0%
    Timeouts: 1082 (50.1%)
    üí∞ PROFITABLE STRATEGY (EV > 0)

  Confusion Matrix:
              Pred Loss  Pred Win
  True Loss         400        49
  True Win          682      1028

  Overfitting Analysis:
    Training Accuracy: 0.653
    Validation Accuracy: 0.661
    Train-Val Gap: -0.008
    ‚úÖ No significant overfitting

üìä Evaluating on Test set...

  Classification Metrics:
    Accuracy: 0.652
    Precision (macro): 0.665
    Recall (macro): 0.730
    F1-Score (macro): 0.631

  Trading Metrics (1:2.0 R:R):
    Win Rate: 100.0% (1014/1014 trades)
    Profit Factor: inf
    Expected Value/Trade: 2.00R
    Trade Accuracy: 100.0%
    Timeouts: 1115 (52.4%)
    üí∞ PROFITABLE STRATEGY (EV > 0)

  Confusion Matrix:
              Pred Loss  Pred Win
  True Loss         437        62
  True Win          678       952

üíæ Model pickle saved to /kaggle/working/Model-output/UNIFIED_RandomForest.pkl
üíæ Metadata saved to /kaggle/working/Model-output/UNIFIED_RandomForest_metadata.json

‚úÖ Model save complete: /kaggle/working/Model-output
‚úÖ RandomForest completed in 16.3s

üöÄ Starting XGBoost training...

================================================================================
Training XGBoost on FULL UNIFIED DATASET
================================================================================

üìä Training on FULL dataset:
  Train: 10,050 samples (11 symbols)
  Val:   2,159 samples
  Test:  2,129 samples
  Selected 53 features
  Remapped labels: [0 1]

üéØ Training with aggressive regularization...

üöÄ Training XGBoost for UNIFIED...
  Training samples: 10,050
  Features: 53

  Train accuracy: 0.712
  Val accuracy:   0.693
  Best iteration: 199

  Top 10 Most Important Features:
    TBM_Bars_to_Hit                         : 0.1923
    TBM_Risk_Per_Trade_ATR                  : 0.0954
    TBM_Reward_Per_Trade_ATR                : 0.0928
    FVG_Mitigated                           : 0.0730
    FVG_Depth_ATR                           : 0.0704
    FVG_Quality_Fuzzy                       : 0.0411
    FVG_Size_Fuzzy_Score                    : 0.0386
    FVG_Distance_to_Price_ATR               : 0.0342
    OB_Bounce_Quality                       : 0.0291
    OB_Bullish_Valid                        : 0.0276

üìä Evaluating on Validation set...

  Classification Metrics:
    Accuracy: 0.693
    Precision (macro): 0.667
    Recall (macro): 0.751
    F1-Score (macro): 0.653

  Trading Metrics (1:2.0 R:R):
    Win Rate: 100.0% (1181/1181 trades)
    Profit Factor: inf
    Expected Value/Trade: 2.00R
    Trade Accuracy: 100.0%
    Timeouts: 978 (45.3%)
    üí∞ PROFITABLE STRATEGY (EV > 0)

  Confusion Matrix:
              Pred Loss  Pred Win
  True Loss         382        67
  True Win          596      1114

  Overfitting Analysis:
    Training Accuracy: 0.712
    Validation Accuracy: 0.693
    Train-Val Gap: 0.019
    ‚úÖ No significant overfitting

üìä Evaluating on Test set...

  Classification Metrics:
    Accuracy: 0.699
    Precision (macro): 0.682
    Recall (macro): 0.752
    F1-Score (macro): 0.669

  Trading Metrics (1:2.0 R:R):
    Win Rate: 100.0% (1137/1137 trades)
    Profit Factor: inf
    Expected Value/Trade: 2.00R
    Trade Accuracy: 100.0%
    Timeouts: 992 (46.6%)
    üí∞ PROFITABLE STRATEGY (EV > 0)

  Confusion Matrix:
              Pred Loss  Pred Win
  True Loss         425        74
  True Win          567      1063

üíæ Model pickle saved to /kaggle/working/Model-output/UNIFIED_XGBoost.pkl
üíæ Metadata saved to /kaggle/working/Model-output/UNIFIED_XGBoost_metadata.json

‚úÖ Model save complete: /kaggle/working/Model-output
‚úÖ XGBoost completed in 1.1s

üß† Starting Neural Network training...

================================================================================
Training Neural Network on FULL UNIFIED DATASET
================================================================================

üìä Training on FULL dataset:
  Train: 10,050 samples (11 symbols)
  Val:   2,159 samples
  Test:  2,129 samples
  Selected 53 features
  Remapped labels: [0 1]

üéØ Training with simplified architecture...

üß† Training Neural Network for UNIFIED...
  Device: cuda
  Training samples: 10,050
  Features: 53
  ‚ö†Ô∏è WARNING: 1 constant features detected!
     These features will not help learning.
  Architecture: 53 -> 64 -> 32 -> 3

  Class distribution:
       0:   2028 ( 20.2%)
       1:   8022 ( 79.8%)

  Detected cleaned binary data (0, 1)
  Will map predictions back to original labels (-1, 1)

  Using 2-class classification
  Training label mapping: {0: 0, 1: 1}
  Prediction label mapping: {0: -1, 1: 1}
  Class distribution: {0: 2028, 1: 8022}
  Class weights: {0: 2.477810650887574, 1: 0.6264023934181002}
  Epoch 10/200 - LR: 0.001000 - Train Loss: 0.6160, Train Acc: 0.694 | Val Loss: 0.6133, Val Acc: 0.753
‚ö†Ô∏è Epoch 20: Exploding gradient detected (norm=1154.85 > 50.0)
  Epoch 20/200 - LR: 0.001000 - Train Loss: 0.6003, Train Acc: 0.700 | Val Loss: 0.5961, Val Acc: 0.713
‚ö†Ô∏è Epoch 22: Exploding gradient detected (norm=747.81 > 50.0)
  Epoch 30/200 - LR: 0.001000 - Train Loss: 0.5924, Train Acc: 0.707 | Val Loss: 0.6033, Val Acc: 0.753
  Epoch 40/200 - LR: 0.000250 - Train Loss: 0.5881, Train Acc: 0.715 | Val Loss: 0.5947, Val Acc: 0.736

  Early stopping at epoch 46 (patience=20)
Learning curves saved to: /kaggle/working/Training_Images/UNIFIED_NN_learning_curves.png
Overfitting metrics saved to: /kaggle/working/Training_Images/UNIFIED_NN_overfitting_metrics.json

============================================================
OVERFITTING MONITOR SUMMARY
============================================================
Status: ‚úì HEALTHY
Train-Val Gap: -1.95% (Threshold: 15%)
Total Epochs: 46
Training Duration: 0:00:47.210069

Final Metrics:
  Train Accuracy: 0.7073
  Val Accuracy:   0.7267
  Train Loss:     0.5880
  Val Loss:       0.5902

Best Epoch (Highest Val Accuracy):
  Epoch:          30
  Train Accuracy: 0.6973
  Val Accuracy:   0.7772
  Train Loss:     0.5960
  Val Loss:       0.6162
============================================================


  ‚ö†Ô∏è Training Warnings (2):
    - Epoch 20: Exploding gradient detected (norm=1154.85 > 50.0)
    - Epoch 22: Exploding gradient detected (norm=747.81 > 50.0)

  Final Train Accuracy: 0.707
  Final Val Accuracy:   0.727
  Train-Val Gap:        -0.019 (-1.9%)

üìä Evaluating on Validation set...

  Classification Metrics:
    Accuracy: 0.039
    Precision (macro): 0.022
    Recall (macro): 0.063
    F1-Score (macro): 0.033

  Trading Metrics (1:2.0 R:R):
    Win Rate: 0.0% (0/869 trades)
    Profit Factor: 0.00
    Expected Value/Trade: -1.00R
    Trade Accuracy: 0.0%
    Timeouts: 1290 (59.7%)
    ‚ö†Ô∏è LOSING STRATEGY (EV < 0)

  Confusion Matrix:
              Pred Loss  Pred Timeout  Pred Win
  True Loss           0           0         0
  True Timeout      364          85         0
  True Win          505        1205         0

üìä Evaluating on Test set...

  Classification Metrics:
    Accuracy: 0.039
    Precision (macro): 0.023
    Recall (macro): 0.056
    F1-Score (macro): 0.033

  Trading Metrics (1:2.0 R:R):
    Win Rate: 0.0% (0/936 trades)
    Profit Factor: 0.00
    Expected Value/Trade: -1.00R
    Trade Accuracy: 0.0%
    Timeouts: 1193 (56.0%)
    ‚ö†Ô∏è LOSING STRATEGY (EV < 0)

  Confusion Matrix:
              Pred Loss  Pred Timeout  Pred Win
  True Loss           0           0         0
  True Timeout      415          84         0
  True Win          521        1109         0

üíæ Model pickle saved to /kaggle/working/Model-output/UNIFIED_NeuralNetwork.pkl
üíæ Metadata saved to /kaggle/working/Model-output/UNIFIED_NeuralNetwork_metadata.json
üíæ Scaler saved to /kaggle/working/Model-output/UNIFIED_NeuralNetwork_scaler.pkl

‚úÖ Model save complete: /kaggle/working/Model-output
‚úÖ Neural Network completed in 49.0s

================================================================================
Training Summary:
  Total Duration: 66.3s (1.1 min)
  Successful Models: 3/3
  Failed Models: 0/3
================================================================================

================================================================================
All training completed in 66.3s (1.1 minutes)
================================================================================

================================================================================
TRAINING SUMMARY REPORT - UNIFIED DATASET
================================================================================

üìä Model Performance:
  Model                Train Acc    Val Acc      Test Acc     Gap        Status              
  ----------------------------------------------------------------------------------------------------
  RandomForest         0.653        0.661        0.652        -0.82%     ‚úÖ Good              
  XGBoost              0.712        0.693        0.699        1.90%      ‚úÖ Good              
  NeuralNetwork        0.000        0.039        0.039        -3.94%     ‚úÖ Good              

üíæ Results saved to: /kaggle/working/Model-output/training_results.json

‚úÖ Training complete!

================================================================================
NEXT STEPS:
================================================================================
1. Review training results in models/trained/training_results.json
2. Check model files: UNIFIED_RandomForest.pkl, UNIFIED_XGBoost.pkl, UNIFIED_NeuralNetwork.pkl
3. Use unified models for predictions on ANY symbol
4. Deploy to production

Models saved in: models/trained/

================================================================================
FINAL STATISTICS
================================================================================
  Approach:             Unified Dataset (All Symbols)
  Total Models:         3
  Successful:           3
  Failed:               0
  Success Rate:         100.0%
  Total Duration:       66.3s (1.1 min)
  Models per Symbol:    1 (unified model works for all)
================================================================================

üéâ Done! Your unified models are ready for deployment!