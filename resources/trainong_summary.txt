================================================================================
SMC MODEL TRAINING - FULL DATASET APPROACH
================================================================================

🎯 Training Strategy:
  - Train on ALL symbols combined (unified dataset)
  - 2,500+ samples (vs 178-295 per symbol)
  - 3 models total (vs 44 models)
  - Better generalization, less overfitting
  - ATR normalization makes features comparable
🔍 Detected Kaggle environment
  ✓ Using cleaned data (optimized for Neural Network)
📂 Data Directory: /kaggle/working/Data-output-clean
📂 Model Output Directory: /kaggle/working/Model-output

🔍 Checking data availability...
  ✓ Train data: /kaggle/working/Data-output-clean/processed_smc_data_train_clean.csv
  ✓ Val data:   /kaggle/working/Data-output-clean/processed_smc_data_val_clean.csv
  ✓ Test data:  /kaggle/working/Data-output-clean/processed_smc_data_test_clean.csv

📊 Dataset Statistics:
  Train samples: 10,050
  Val samples:   2,159
  Test samples:  2,129
  Total:         14,338
  Symbols:       11
  Features:      78

================================================================================
STARTING UNIFIED TRAINING
================================================================================

################################################################################
# Training All Models on UNIFIED DATASET
################################################################################

🎯 Strategy: Train on ALL data for maximum generalization
   Core Models: RandomForest, XGBoost, NeuralNetwork
   LSTM: Disabled (use --include-lstm to enable)

🌲 Starting RandomForest training...

================================================================================
Training Random Forest on FULL UNIFIED DATASET
================================================================================

📊 Training on FULL dataset:
  Train: 10,050 samples (11 symbols)
  Val:   2,159 samples
  Test:  2,129 samples
  Selected 53 features
  Remapped labels: [0 1]

🔄 Performing 5-fold cross-validation...

🔄 Performing 5-fold cross-validation...

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.650
  Val accuracy:   0.663
  Train-Val gap:  -0.013
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 1/5: Accuracy=0.663, F1=0.625

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.654
  Val accuracy:   0.648
  Train-Val gap:  0.006
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 2/5: Accuracy=0.648, F1=0.610

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.652
  Val accuracy:   0.659
  Train-Val gap:  -0.008
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 3/5: Accuracy=0.659, F1=0.622

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.652
  Val accuracy:   0.658
  Train-Val gap:  -0.006
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 4/5: Accuracy=0.658, F1=0.621

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.657
  Val accuracy:   0.638
  Train-Val gap:  0.019
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 5/5: Accuracy=0.638, F1=0.603

  Cross-Validation Results:
    Mean Accuracy: 0.653 ± 0.009
    Min Accuracy:  0.638
    Max Accuracy:  0.663
    Range:         0.025
    Mean F1-Score: 0.616 ± 0.008
    ✅ STABLE: Std dev 0.009 ≤ 0.10

    Poor-Performing Folds (below mean - std):
      Fold 5: 0.638 (deviation: -0.015)

📈 Cross-Validation Results:
  Mean Accuracy: 0.6532 ± 0.0091
  Stability: ✅ Stable

🎯 Training final model...

🌲 Training Random Forest for UNIFIED...
  Training samples: 10,050
  Features: 53

  🔄 Performing cross-validation...

🔄 Performing 5-fold cross-validation...

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.650
  Val accuracy:   0.663
  Train-Val gap:  -0.013
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 1/5: Accuracy=0.663, F1=0.625

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.654
  Val accuracy:   0.648
  Train-Val gap:  0.006
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 2/5: Accuracy=0.648, F1=0.610

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.652
  Val accuracy:   0.659
  Train-Val gap:  -0.008
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 3/5: Accuracy=0.659, F1=0.622

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.652
  Val accuracy:   0.658
  Train-Val gap:  -0.006
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 4/5: Accuracy=0.658, F1=0.621

🌲 Training Random Forest for UNIFIED...
  Training samples: 8,040
  Features: 53

  Train accuracy: 0.657
  Val accuracy:   0.638
  Train-Val gap:  0.019
  ✅ Good generalization (gap ≤ 15%)

  Feature importance computed (feature names not available)
  Fold 5/5: Accuracy=0.638, F1=0.603

  Cross-Validation Results:
    Mean Accuracy: 0.653 ± 0.009
    Min Accuracy:  0.638
    Max Accuracy:  0.663
    Range:         0.025
    Mean F1-Score: 0.616 ± 0.008
    ✅ STABLE: Std dev 0.009 ≤ 0.10

    Poor-Performing Folds (below mean - std):
      Fold 5: 0.638 (deviation: -0.015)

  Train accuracy: 0.653
  Val accuracy:   0.661
  Train-Val gap:  -0.008
  ✅ Good generalization (gap ≤ 15%)

  Top 10 Most Important Features:
    TBM_Bars_to_Hit                         : 0.2863
    TBM_Reward_Per_Trade_ATR                : 0.1346
    TBM_Risk_Per_Trade_ATR                  : 0.0980
    FVG_Depth_ATR_ZScore                    : 0.0795
    FVG_Quality_Fuzzy                       : 0.0764
    FVG_Depth_ATR                           : 0.0653
    FVG_Size_Fuzzy_Score                    : 0.0595
    FVG_Distance_to_Price_ATR_ZScore        : 0.0468
    FVG_Distance_to_Price_ATR               : 0.0446
    FVG_Mitigated                           : 0.0428

📊 Evaluating on Validation set...

  Classification Metrics:
    Accuracy: 0.661
    Precision (macro): 0.662
    Recall (macro): 0.746
    F1-Score (macro): 0.630

  Trading Metrics (1:2.0 R:R):
    Win Rate: 100.0% (1077/1077 trades)
    Profit Factor: inf
    Expected Value/Trade: 2.00R
    Trade Accuracy: 100.0%
    Timeouts: 1082 (50.1%)
    💰 PROFITABLE STRATEGY (EV > 0)

  Confusion Matrix:
              Pred Loss  Pred Win
  True Loss         400        49
  True Win          682      1028

  Overfitting Analysis:
    Training Accuracy: 0.653
    Validation Accuracy: 0.661
    Train-Val Gap: -0.008
    ✅ No significant overfitting

📊 Evaluating on Test set...

  Classification Metrics:
    Accuracy: 0.652
    Precision (macro): 0.665
    Recall (macro): 0.730
    F1-Score (macro): 0.631

  Trading Metrics (1:2.0 R:R):
    Win Rate: 100.0% (1014/1014 trades)
    Profit Factor: inf
    Expected Value/Trade: 2.00R
    Trade Accuracy: 100.0%
    Timeouts: 1115 (52.4%)
    💰 PROFITABLE STRATEGY (EV > 0)

  Confusion Matrix:
              Pred Loss  Pred Win
  True Loss         437        62
  True Win          678       952

💾 Model pickle saved to /kaggle/working/Model-output/UNIFIED_RandomForest.pkl
💾 Metadata saved to /kaggle/working/Model-output/UNIFIED_RandomForest_metadata.json

✅ Model save complete: /kaggle/working/Model-output
✅ RandomForest completed in 15.8s

🚀 Starting XGBoost training...

================================================================================
Training XGBoost on FULL UNIFIED DATASET
================================================================================

📊 Training on FULL dataset:
  Train: 10,050 samples (11 symbols)
  Val:   2,159 samples
  Test:  2,129 samples
  Selected 53 features
  Remapped labels: [0 1]

🎯 Training with aggressive regularization...

🚀 Training XGBoost for UNIFIED...
  Training samples: 10,050
  Features: 53

  Train accuracy: 0.712
  Val accuracy:   0.693
  Best iteration: 199

  Top 10 Most Important Features:
    TBM_Bars_to_Hit                         : 0.1923
    TBM_Risk_Per_Trade_ATR                  : 0.0954
    TBM_Reward_Per_Trade_ATR                : 0.0928
    FVG_Mitigated                           : 0.0730
    FVG_Depth_ATR                           : 0.0704
    FVG_Quality_Fuzzy                       : 0.0411
    FVG_Size_Fuzzy_Score                    : 0.0386
    FVG_Distance_to_Price_ATR               : 0.0342
    OB_Bounce_Quality                       : 0.0291
    OB_Bullish_Valid                        : 0.0276

📊 Evaluating on Validation set...

  Classification Metrics:
    Accuracy: 0.693
    Precision (macro): 0.667
    Recall (macro): 0.751
    F1-Score (macro): 0.653

  Trading Metrics (1:2.0 R:R):
    Win Rate: 100.0% (1181/1181 trades)
    Profit Factor: inf
    Expected Value/Trade: 2.00R
    Trade Accuracy: 100.0%
    Timeouts: 978 (45.3%)
    💰 PROFITABLE STRATEGY (EV > 0)

  Confusion Matrix:
              Pred Loss  Pred Win
  True Loss         382        67
  True Win          596      1114

  Overfitting Analysis:
    Training Accuracy: 0.712
    Validation Accuracy: 0.693
    Train-Val Gap: 0.019
    ✅ No significant overfitting

📊 Evaluating on Test set...

  Classification Metrics:
    Accuracy: 0.699
    Precision (macro): 0.682
    Recall (macro): 0.752
    F1-Score (macro): 0.669

  Trading Metrics (1:2.0 R:R):
    Win Rate: 100.0% (1137/1137 trades)
    Profit Factor: inf
    Expected Value/Trade: 2.00R
    Trade Accuracy: 100.0%
    Timeouts: 992 (46.6%)
    💰 PROFITABLE STRATEGY (EV > 0)

  Confusion Matrix:
              Pred Loss  Pred Win
  True Loss         425        74
  True Win          567      1063

💾 Model pickle saved to /kaggle/working/Model-output/UNIFIED_XGBoost.pkl
💾 Metadata saved to /kaggle/working/Model-output/UNIFIED_XGBoost_metadata.json

✅ Model save complete: /kaggle/working/Model-output
✅ XGBoost completed in 1.1s

🧠 Starting Neural Network training...

================================================================================
Training Neural Network on FULL UNIFIED DATASET
================================================================================

📊 Training on FULL dataset:
  Train: 10,050 samples (11 symbols)
  Val:   2,159 samples
  Test:  2,129 samples
  Selected 53 features
  Remapped labels: [0 1]

🎯 Training with simplified architecture...

🧠 Training Neural Network for UNIFIED...
  Device: cuda
  Training samples: 10,050
  Features: 53
  ⚠️ WARNING: 1 constant features detected!
     These features will not help learning.
  Architecture: 53 -> 64 -> 32 -> 3

  Class distribution:
       0:   2028 ( 20.2%)
       1:   8022 ( 79.8%)

  Using 2-class classification
  Label mapping: {0: 0, 1: 1}
  Class distribution: {0: 2028, 1: 8022}
  Class weights: {0: 2.477810650887574, 1: 0.6264023934181002}
  Epoch 10/200 - LR: 0.001000 - Train Loss: 0.6171, Train Acc: 0.699 | Val Loss: 0.6075, Val Acc: 0.736
  Epoch 20/200 - LR: 0.001000 - Train Loss: 0.6022, Train Acc: 0.704 | Val Loss: 0.6141, Val Acc: 0.771
  Epoch 30/200 - LR: 0.000500 - Train Loss: 0.5943, Train Acc: 0.699 | Val Loss: 0.5926, Val Acc: 0.721
  Epoch 40/200 - LR: 0.000125 - Train Loss: 0.5872, Train Acc: 0.713 | Val Loss: 0.5893, Val Acc: 0.720
  Epoch 50/200 - LR: 0.000125 - Train Loss: 0.5888, Train Acc: 0.712 | Val Loss: 0.6023, Val Acc: 0.759
  Epoch 60/200 - LR: 0.000031 - Train Loss: 0.5928, Train Acc: 0.713 | Val Loss: 0.5894, Val Acc: 0.717
  Epoch 70/200 - LR: 0.000016 - Train Loss: 0.5884, Train Acc: 0.714 | Val Loss: 0.5891, Val Acc: 0.714
⚠️ Epoch 77: Exploding gradient detected (norm=2876.51 > 50.0)
  Epoch 80/200 - LR: 0.000004 - Train Loss: 0.5874, Train Acc: 0.714 | Val Loss: 0.6124, Val Acc: 0.565

  Early stopping at epoch 81 (patience=20)
Learning curves saved to: /kaggle/working/Training_Images/UNIFIED_NN_learning_curves.png
Overfitting metrics saved to: /kaggle/working/Training_Images/UNIFIED_NN_overfitting_metrics.json

============================================================
OVERFITTING MONITOR SUMMARY
============================================================
Status: ✓ HEALTHY
Train-Val Gap: 0.09% (Threshold: 15%)
Total Epochs: 81
Training Duration: 0:01:19.903360

Final Metrics:
  Train Accuracy: 0.7123
  Val Accuracy:   0.7114
  Train Loss:     0.5915
  Val Loss:       0.5901

Best Epoch (Highest Val Accuracy):
  Epoch:          55
  Train Accuracy: 0.7093
  Val Accuracy:   0.8045
  Train Loss:     0.5933
  Val Loss:       0.6330
============================================================


  ⚠️ Training Warnings (1):
    - Epoch 77: Exploding gradient detected (norm=2876.51 > 50.0)

  Final Train Accuracy: 0.712
  Final Val Accuracy:   0.711
  Train-Val Gap:        0.001 (0.1%)

📊 Evaluating on Validation set...

  Classification Metrics:
    Accuracy: 0.038
    Precision (macro): 0.022
    Recall (macro): 0.060
    F1-Score (macro): 0.032

  Trading Metrics (1:2.0 R:R):
    Win Rate: 0.0% (0/910 trades)
    Profit Factor: 0.00
    Expected Value/Trade: -1.00R
    Trade Accuracy: 0.0%
    Timeouts: 1249 (57.9%)
    ⚠️ LOSING STRATEGY (EV < 0)

  Confusion Matrix:
              Pred Loss  Pred Timeout  Pred Win
  True Loss           0           0         0
  True Timeout      368          81         0
  True Win          542        1168         0

📊 Evaluating on Test set...

  Classification Metrics:
    Accuracy: 0.036
    Precision (macro): 0.022
    Recall (macro): 0.051
    F1-Score (macro): 0.030

  Trading Metrics (1:2.0 R:R):
    Win Rate: 0.0% (0/957 trades)
    Profit Factor: 0.00
    Expected Value/Trade: -1.00R
    Trade Accuracy: 0.0%
    Timeouts: 1172 (55.0%)
    ⚠️ LOSING STRATEGY (EV < 0)

  Confusion Matrix:
              Pred Loss  Pred Timeout  Pred Win
  True Loss           0           0         0
  True Timeout      423          76         0
  True Win          534        1096         0

💾 Model pickle saved to /kaggle/working/Model-output/UNIFIED_NeuralNetwork.pkl
💾 Metadata saved to /kaggle/working/Model-output/UNIFIED_NeuralNetwork_metadata.json
💾 Scaler saved to /kaggle/working/Model-output/UNIFIED_NeuralNetwork_scaler.pkl

✅ Model save complete: /kaggle/working/Model-output
✅ Neural Network completed in 81.5s

================================================================================
Training Summary:
  Total Duration: 98.4s (1.6 min)
  Successful Models: 3/3
  Failed Models: 0/3
================================================================================

================================================================================
All training completed in 98.4s (1.6 minutes)
================================================================================

================================================================================
TRAINING SUMMARY REPORT - UNIFIED DATASET
================================================================================

📊 Model Performance:
  Model                Train Acc    Val Acc      Test Acc     Gap        Status              
  ----------------------------------------------------------------------------------------------------
  RandomForest         0.653        0.661        0.652        -0.82%     ✅ Good              
  XGBoost              0.712        0.693        0.699        1.90%      ✅ Good              
  NeuralNetwork        0.000        0.038        0.036        -3.75%     ✅ Good              

💾 Results saved to: /kaggle/working/Model-output/training_results.json

✅ Training complete!

================================================================================
NEXT STEPS:
================================================================================
1. Review training results in models/trained/training_results.json
2. Check model files: UNIFIED_RandomForest.pkl, UNIFIED_XGBoost.pkl, UNIFIED_NeuralNetwork.pkl
3. Use unified models for predictions on ANY symbol
4. Deploy to production

Models saved in: models/trained/

================================================================================
FINAL STATISTICS
================================================================================
  Approach:             Unified Dataset (All Symbols)
  Total Models:         3
  Successful:           3
  Failed:               0
  Success Rate:         100.0%
  Total Duration:       98.4s (1.6 min)
  Models per Symbol:    1 (unified model works for all)
================================================================================

🎉 Done! Your unified models are ready for deployment!