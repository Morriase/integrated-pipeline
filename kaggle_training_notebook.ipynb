{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2586792",
   "metadata": {},
   "source": [
    "# Black Ice Integrated Pipeline - Kaggle Training\n",
    "\n",
    "This notebook runs the complete integrated pipeline for training all models including temporal LSTM/Transformer models.\n",
    "\n",
    "## Setup\n",
    "1. Upload all Python files from your project\n",
    "2. Upload training_data.csv\n",
    "3. Run the cells below\n",
    "4. Download the trained models from Model_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install scikit-learn pandas numpy matplotlib seaborn plotly\n",
    "!pip install lightgbm xgboost catboost\n",
    "!pip install flask requests\n",
    "!pip install jupyter ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project structure\n",
    "import os\n",
    "os.makedirs('Model_output', exist_ok=True)\n",
    "os.makedirs('Model_output/deployment', exist_ok=True)\n",
    "os.makedirs('Model_output/ensemble', exist_ok=True)\n",
    "\n",
    "print(\"Project structure created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd973034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your files here (use Kaggle's file upload interface)\n",
    "# Make sure to upload:\n",
    "# - integrated_advanced_pipeline.py\n",
    "# - production_ensemble_pipeline.py\n",
    "# - advanced_temporal_architecture.py\n",
    "# - enhanced_multitf_pipeline.py\n",
    "# - feature_engineering_smc_institutional.py\n",
    "# - model_export.py\n",
    "# - learning_curve_plotter.py\n",
    "# - temporal_validation.py\n",
    "# - recovery_mechanism.py\n",
    "# - training_data.csv\n",
    "\n",
    "print(\"Upload your files to the Kaggle notebook environment\")\n",
    "print(\"Files should be in the root directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify files are uploaded\n",
    "import os\n",
    "files_to_check = [\n",
    "    'integrated_advanced_pipeline.py',\n",
    "    'production_ensemble_pipeline.py',\n",
    "    'advanced_temporal_architecture.py',\n",
    "    'enhanced_multitf_pipeline.py',\n",
    "    'feature_engineering_smc_institutional.py',\n",
    "    'model_export.py',\n",
    "    'learning_curve_plotter.py',\n",
    "    'temporal_validation.py',\n",
    "    'recovery_mechanism.py',\n",
    "    'training_data.csv'\n",
    "]\n",
    "\n",
    "missing_files = [f for f in files_to_check if not os.path.exists(f)]\n",
    "if missing_files:\n",
    "    print(f\"Missing files: {missing_files}\")\n",
    "    print(\"Please upload the missing files\")\n",
    "else:\n",
    "    print(\"All required files are present!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d595b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the integrated pipeline\n",
    "from integrated_advanced_pipeline import main\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure the pipeline\n",
    "config = {\n",
    "    'data_path': 'training_data.csv',\n",
    "    'save_path': 'Model_output',\n",
    "    'sequence_length': 20,\n",
    "    'batch_size': 64,  # Smaller batch size for Kaggle\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 1e-3,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"Using device: {config['device']}\")\n",
    "print(\"Starting integrated pipeline training...\")\n",
    "\n",
    "# Run the pipeline\n",
    "system, results = main(config)\n",
    "\n",
    "print(\"\\n✅ Training completed successfully!\")\n",
    "print(f\"Models saved to: {config['save_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7af8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify models were created\n",
    "import os\n",
    "\n",
    "print(\"Checking created models...\")\n",
    "\n",
    "# Check deployment models\n",
    "deployment_dir = 'Model_output/deployment'\n",
    "if os.path.exists(deployment_dir):\n",
    "    deployment_files = os.listdir(deployment_dir)\n",
    "    print(f\"\\nDeployment models ({len(deployment_files)} files):\")\n",
    "    for f in sorted(deployment_files):\n",
    "        print(f\"  - {f}\")\n",
    "\n",
    "# Check ensemble models\n",
    "ensemble_dir = 'Model_output/ensemble'\n",
    "if os.path.exists(ensemble_dir):\n",
    "    ensemble_files = os.listdir(ensemble_dir)\n",
    "    print(f\"\\nEnsemble models ({len(ensemble_files)} files):\")\n",
    "    for f in sorted(ensemble_files):\n",
    "        print(f\"  - {f}\")\n",
    "\n",
    "# Check for temporal models specifically\n",
    "temporal_models = [f for f in ensemble_files if 'lstm' in f.lower() or 'transformer' in f.lower()]\n",
    "if temporal_models:\n",
    "    print(f\"\\n✅ Temporal models found: {temporal_models}\")\n",
    "else:\n",
    "    print(\"\\n❌ No temporal models found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3479edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model loading\n",
    "try:\n",
    "    from model_rest_server_proper import ProperModelServer\n",
    "    \n",
    "    print(\"Testing model server initialization...\")\n",
    "    server = ProperModelServer('Model_output')\n",
    "    \n",
    "    print(\"\\n✅ Server initialized successfully!\")\n",
    "    print(f\"Loaded models: {len(server.models['pytorch'])} PyTorch, {len(server.models['sklearn'])} sklearn, {len(server.models['temporal'])} temporal\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Server initialization failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04179bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the trained models\n",
    "import zipfile\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Create zip file of Model_output\n",
    "def create_zip(zip_name, directory):\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file), \n",
    "                          os.path.relpath(os.path.join(root, file), directory))\n",
    "    return zip_name\n",
    "\n",
    "# Create and download zip\n",
    "zip_file = create_zip('trained_models.zip', 'Model_output')\n",
    "print(f\"Created zip file: {zip_file}\")\n",
    "\n",
    "# Display download link\n",
    "FileLink(zip_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffc88a",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. **Upload Files**: Use Kaggle's file upload interface to upload all your Python files and training_data.csv\n",
    "2. **Run Cells**: Execute the cells in order\n",
    "3. **Monitor Training**: The pipeline will train all models including temporal LSTM/Transformer\n",
    "4. **Download Results**: Use the download link to get your trained models\n",
    "5. **Copy to Local**: Download the zip file and extract to your local Python project\n",
    "\n",
    "## Expected Output\n",
    "- 4 PyTorch feedforward models (TorchScript .pt files)\n",
    "- 4 sklearn models (.pkl files)\n",
    "- 2 temporal models (LSTM and Transformer state_dict .pth files)\n",
    "- Feature scalers and ensemble configuration\n",
    "\n",
    "## Troubleshooting\n",
    "- If you get CUDA out of memory, reduce batch_size in config\n",
    "- If training is too slow, reduce epochs\n",
    "- Make sure all required files are uploaded"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
