"""
Kaggle-Optimized Pipeline Runner
=================================

This script is specifically configured for Kaggle notebooks with:
- Input: /kaggle/input/ob-ai-model-2-dataset/Data/mt5_exports
- Data Output: /kaggle/working/Data-output
- Model Output: /kaggle/working/Model-output

Usage in Kaggle Notebook:
    !python run_kaggle_pipeline.py
    
Or run in cells:
    %run run_kaggle_pipeline.py
"""

from pathlib import Path
import sys
import time
from datetime import datetime

# Kaggle paths
KAGGLE_INPUT = '/kaggle/input/ob-ai-model-2-dataset/Data/mt5_exports'
KAGGLE_DATA_OUTPUT = '/kaggle/working/Data-output'
KAGGLE_DATA_OUTPUT_CLEAN = '/kaggle/working/Data-output-clean'  # Cleaned data for NN
KAGGLE_MODEL_OUTPUT = '/kaggle/working/Model-output'


def setup_kaggle_environment():
    """Setup Kaggle environment and verify paths"""
    print("=" * 80)
    print("KAGGLE ENVIRONMENT SETUP")
    print("=" * 80)
    
    # Verify input data exists
    input_path = Path(KAGGLE_INPUT)
    if not input_path.exists():
        print(f"‚ùå ERROR: Input data not found at {KAGGLE_INPUT}")
        print("\nPlease ensure the dataset is attached to your Kaggle notebook:")
        print("  1. Click 'Add Data' in Kaggle")
        print("  2. Search for 'ob-ai-model-2-dataset'")
        print("  3. Add to notebook")
        sys.exit(1)
    
    print(f"‚úì Input data found: {KAGGLE_INPUT}")
    
    # Count input files
    csv_files = list(input_path.glob('*.csv'))
    print(f"  Found {len(csv_files)} CSV files")
    
    # Create output directories
    Path(KAGGLE_DATA_OUTPUT).mkdir(parents=True, exist_ok=True)
    Path(KAGGLE_MODEL_OUTPUT).mkdir(parents=True, exist_ok=True)
    
    print(f"‚úì Data output directory: {KAGGLE_DATA_OUTPUT}")
    print(f"‚úì Model output directory: {KAGGLE_MODEL_OUTPUT}")
    
    return True


def run_data_pipeline():
    """Run data preparation pipeline"""
    print("\n" + "=" * 80)
    print("STEP 1: DATA PREPARATION PIPELINE")
    print("=" * 80)
    
    from consolidate_mt5_data import consolidate_mt5_exports
    from data_preparation_pipeline import SMCDataPipeline
    
    start_time = time.time()
    
    # Consolidate MT5 exports
    print("\nüìä Consolidating MT5 export files...")
    consolidated_df = consolidate_mt5_exports(
        input_dir=KAGGLE_INPUT,
        output_file=f'{KAGGLE_DATA_OUTPUT}/consolidated_ohlc_data.csv',
        symbols=None,  # ALL symbols
        timeframes=None  # ALL timeframes
    )
    
    consolidation_time = time.time() - start_time
    print(f"‚úì Consolidation complete: {consolidation_time:.1f}s")
    
    # Process SMC features
    print("\nüîß Processing SMC features...")
    pipeline = SMCDataPipeline(
        base_timeframe='M15',
        higher_timeframes=['H1', 'H4'],
        atr_period=14,
        rr_ratio=2.0,
        lookforward=20,
        fuzzy_quality_threshold=0.2
    )
    
    processed_df = pipeline.run_pipeline(
        input_path=f'{KAGGLE_DATA_OUTPUT}/consolidated_ohlc_data.csv',
        output_path=f'{KAGGLE_DATA_OUTPUT}/processed_smc_data.csv',
        save_splits=True
    )
    
    total_time = time.time() - start_time
    print(f"\n‚úì Data pipeline complete: {total_time:.1f}s ({total_time/60:.1f} min)")
    
    return processed_df


def clean_data_for_nn():
    """Clean data for Neural Network training (Step 1.5)"""
    print("\n" + "=" * 80)
    print("STEP 1.5: DATA CLEANING FOR NEURAL NETWORK")
    print("=" * 80)
    
    from fix_nn_training import prepare_nn_data
    
    start_time = time.time()
    
    # Clean the data
    train_clean, val_clean, test_clean = prepare_nn_data(
        train_path=f'{KAGGLE_DATA_OUTPUT}/processed_smc_data_train.csv',
        val_path=f'{KAGGLE_DATA_OUTPUT}/processed_smc_data_val.csv',
        test_path=f'{KAGGLE_DATA_OUTPUT}/processed_smc_data_test.csv'
    )
    
    # Save cleaned data
    Path(KAGGLE_DATA_OUTPUT_CLEAN).mkdir(parents=True, exist_ok=True)
    
    print(f"\nüíæ Saving cleaned data to: {KAGGLE_DATA_OUTPUT_CLEAN}")
    train_clean.to_csv(f'{KAGGLE_DATA_OUTPUT_CLEAN}/processed_smc_data_train_clean.csv', index=False)
    val_clean.to_csv(f'{KAGGLE_DATA_OUTPUT_CLEAN}/processed_smc_data_val_clean.csv', index=False)
    test_clean.to_csv(f'{KAGGLE_DATA_OUTPUT_CLEAN}/processed_smc_data_test_clean.csv', index=False)
    
    total_time = time.time() - start_time
    print(f"\n‚úì Data cleaning complete: {total_time:.1f}s")
    
    return train_clean, val_clean, test_clean


def run_model_training(include_lstm=False):
    """Run model training pipeline"""
    print("\n" + "=" * 80)
    print("STEP 2: MODEL TRAINING PIPELINE")
    print("=" * 80)
    
    from train_all_models import UnifiedModelTrainer
    
    start_time = time.time()
    
    # Use cleaned data if available
    if Path(KAGGLE_DATA_OUTPUT_CLEAN).exists():
        data_dir = KAGGLE_DATA_OUTPUT_CLEAN
        print(f"  ‚úì Using cleaned data for better NN performance")
    else:
        data_dir = KAGGLE_DATA_OUTPUT
        print(f"  ‚ö†Ô∏è Using raw data (NN may underperform)")
    
    # Initialize trainer
    trainer = UnifiedModelTrainer(
        data_dir=data_dir,
        output_dir=KAGGLE_MODEL_OUTPUT,
        include_lstm=include_lstm
    )
    
    # Check data availability
    if not trainer.check_data_availability():
        print("\n‚ùå Training data not found!")
        print("Please run data pipeline first.")
        sys.exit(1)
    
    # Train all models
    results = trainer.train_all_models()
    
    # Generate summary
    trainer.generate_summary_report()
    
    total_time = time.time() - start_time
    print(f"\n‚úì Model training complete: {total_time:.1f}s ({total_time/60:.1f} min)")
    
    return results


def main():
    """Main execution function"""
    print("\n" + "=" * 80)
    print("KAGGLE SMC MODEL TRAINING PIPELINE")
    print("=" * 80)
    print(f"\nStarted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    overall_start = time.time()
    
    # Setup environment
    if not setup_kaggle_environment():
        sys.exit(1)
    
    # Run data pipeline
    try:
        processed_df = run_data_pipeline()
        print(f"\n‚úÖ Data pipeline successful: {len(processed_df):,} samples")
    except Exception as e:
        print(f"\n‚ùå Data pipeline failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # Clean data for Neural Network
    try:
        train_clean, val_clean, test_clean = clean_data_for_nn()
        print(f"\n‚úÖ Data cleaning successful: {len(train_clean):,} clean samples")
    except Exception as e:
        print(f"\n‚ö†Ô∏è Data cleaning failed: {e}")
        print("   Continuing with raw data (NN may underperform)")
        import traceback
        traceback.print_exc()
    
    # Run model training
    try:
        # Check if user wants LSTM (can be set via environment variable)
        include_lstm = '--include-lstm' in sys.argv
        
        results = run_model_training(include_lstm=include_lstm)
        print(f"\n‚úÖ Model training successful")
    except Exception as e:
        print(f"\n‚ùå Model training failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # Final summary
    overall_time = time.time() - overall_start
    print("\n" + "=" * 80)
    print("PIPELINE COMPLETE")
    print("=" * 80)
    print(f"\nTotal execution time: {overall_time:.1f}s ({overall_time/60:.1f} min)")
    print(f"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print("\nüìÅ Output Files:")
    print(f"\nData Output ({KAGGLE_DATA_OUTPUT}):")
    print("  - consolidated_ohlc_data.csv")
    print("  - processed_smc_data.csv")
    print("  - processed_smc_data_train.csv")
    print("  - processed_smc_data_val.csv")
    print("  - processed_smc_data_test.csv")
    
    print(f"\nModel Output ({KAGGLE_MODEL_OUTPUT}):")
    print("  - UNIFIED_RandomForest.pkl")
    print("  - UNIFIED_XGBoost.pkl")
    print("  - UNIFIED_NeuralNetwork.pkl")
    if include_lstm:
        print("  - UNIFIED_LSTM.pkl")
    print("  - training_results.json")
    
    print("\nüéâ All done! Models are ready for inference.")


if __name__ == "__main__":
    """
    Run complete pipeline on Kaggle
    
    Usage:
        # Without LSTM (recommended)
        !python run_kaggle_pipeline.py
        
        # With LSTM (experimental)
        !python run_kaggle_pipeline.py --include-lstm
    """
    main()
